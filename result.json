{
    "-1983619672205496581": {
        "dataset": "abalone",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "regression",
        "parameters": "iterations_10_learning_rate_0.03_max_depth_6_",
        "scores": [
            3.24294,
            3.19003,
            3.14026,
            3.09172,
            3.04524,
            3.00128,
            2.95913,
            2.91798,
            2.87908,
            2.84184
        ],
        "time_series": [
            5.537181,
            5.539176,
            5.541171,
            5.543167,
            5.545161,
            5.547155,
            5.548152,
            5.54915,
            5.551145,
            5.553139
        ],
        "duration": 0.02991938591003418
    },
    "8129347296199356851": {
        "dataset": "abalone",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "regression",
        "parameters": "iterations_10_learning_rate_0.07_max_depth_6_",
        "scores": [
            3.17122,
            3.05504,
            2.95409,
            2.86166,
            2.77707,
            2.70374,
            2.63634,
            2.57536,
            2.52327,
            2.48072
        ],
        "time_series": [
            15.564911,
            15.566905,
            15.567902,
            15.569897,
            15.571892,
            15.573886,
            15.574884,
            15.576878,
            15.578873,
            15.57987
        ],
        "duration": 0.0249330997467041
    },
    "-93449137173588180": {
        "dataset": "abalone",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "regression",
        "parameters": "iterations_10_learning_rate_0.15_max_depth_6_",
        "scores": [
            3.03322,
            2.82284,
            2.65957,
            2.53484,
            2.43898,
            2.37132,
            2.31161,
            2.26836,
            2.23918,
            2.21614
        ],
        "time_series": [
            17.122748,
            17.124742,
            17.127734,
            17.143694,
            17.161647,
            17.16663,
            17.172619,
            17.176607,
            17.179596,
            17.18159
        ],
        "duration": 0.06781959533691406
    },
    "-6531097380954895593": {
        "dataset": "letters",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "multiclass",
        "parameters": "iterations_10_learning_rate_0.03_max_depth_6_",
        "scores": [
            0.16525,
            0.1475,
            0.13225,
            0.129,
            0.12325,
            0.12175,
            0.11675,
            0.1135,
            0.111,
            0.1065
        ],
        "time_series": [
            17.634379,
            17.698209,
            17.748076,
            17.79894,
            17.85878,
            17.915628,
            17.964497,
            18.006386,
            18.039298,
            18.071212
        ],
        "duration": 0.6283190250396729
    },
    "-1704223713961862837": {
        "dataset": "letters",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "multiclass",
        "parameters": "iterations_10_learning_rate_0.07_max_depth_6_",
        "scores": [
            0.15275,
            0.133,
            0.1215,
            0.1135,
            0.10325,
            0.09925,
            0.09475,
            0.0895,
            0.088,
            0.087
        ],
        "time_series": [
            18.209842,
            18.265692,
            18.315559,
            18.36742,
            18.412301,
            18.447207,
            18.482114,
            18.516024,
            18.55093,
            18.585837
        ],
        "duration": 0.5066452026367188
    },
    "1798864471356190395": {
        "dataset": "letters",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "multiclass",
        "parameters": "iterations_10_learning_rate_0.15_max_depth_6_",
        "scores": [
            0.14975,
            0.1245,
            0.10825,
            0.09575,
            0.09175,
            0.0875,
            0.08275,
            0.07625,
            0.075,
            0.0725
        ],
        "time_series": [
            18.729462,
            18.771342,
            18.828189,
            18.886035,
            19.010702,
            19.059571,
            19.10844,
            19.162296,
            19.211165,
            19.259038
        ],
        "duration": 0.6791839599609375
    },
    "-2085115921253422465": {
        "dataset": "abalone",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "regression",
        "parameters": "iterations_10_learning_rate_0.03_max_depth_6_",
        "scores": [
            3.24294,
            3.19003,
            3.14026,
            3.09172,
            3.04524,
            3.00128,
            2.95913,
            2.91798,
            2.87908,
            2.84184
        ],
        "time_series": [
            32.470724,
            32.472719,
            32.475713,
            32.478706,
            32.480697,
            32.482692,
            32.484688,
            32.486681,
            32.489674,
            32.49067
        ],
        "duration": 0.035903215408325195
    },
    "6836698938908747612": {
        "dataset": "abalone",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "regression",
        "parameters": "iterations_10_learning_rate_0.07_max_depth_6_",
        "scores": [
            3.17122,
            3.05504,
            2.95409,
            2.86166,
            2.77707,
            2.70374,
            2.63634,
            2.57536,
            2.52327,
            2.48072
        ],
        "time_series": [
            32.512611,
            32.514606,
            32.5166,
            32.518596,
            32.519593,
            32.522591,
            32.526575,
            32.529567,
            32.531563,
            32.534555
        ],
        "duration": 0.029920101165771484
    },
    "2392562315191970949": {
        "dataset": "abalone",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "regression",
        "parameters": "iterations_10_learning_rate_0.15_max_depth_6_",
        "scores": [
            3.03322,
            2.82284,
            2.65957,
            2.53484,
            2.43898,
            2.37132,
            2.31161,
            2.26836,
            2.23918,
            2.21614
        ],
        "time_series": [
            32.580431,
            32.583422,
            32.586415,
            32.588409,
            32.590403,
            32.594396,
            32.597389,
            32.601412,
            32.603369,
            32.605367
        ],
        "duration": 0.03191494941711426
    },
    "5342117988697284236": {
        "dataset": "letters",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "multiclass",
        "parameters": "iterations_10_learning_rate_0.03_max_depth_6_",
        "scores": [
            0.16525,
            0.1475,
            0.13225,
            0.129,
            0.12325,
            0.12175,
            0.11675,
            0.1135,
            0.111,
            0.1065
        ],
        "time_series": [
            33.036212,
            33.096052,
            33.146917,
            33.181823,
            33.224708,
            33.263605,
            33.298511,
            33.331423,
            33.36633,
            33.403231
        ],
        "duration": 0.5405724048614502
    },
    "-2756449888103747108": {
        "dataset": "letters",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "multiclass",
        "parameters": "iterations_10_learning_rate_0.07_max_depth_6_",
        "scores": [
            0.15275,
            0.133,
            0.1215,
            0.1135,
            0.10325,
            0.09925,
            0.09475,
            0.0895,
            0.088,
            0.087
        ],
        "time_series": [
            33.553833,
            33.602698,
            33.637605,
            33.671514,
            33.705424,
            33.742325,
            33.776234,
            33.817125,
            33.855024,
            33.889931
        ],
        "duration": 0.46774768829345703
    },
    "8396211059860581687": {
        "dataset": "letters",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "multiclass",
        "parameters": "iterations_10_learning_rate_0.15_max_depth_6_",
        "scores": [
            0.14975,
            0.1245,
            0.10825,
            0.09575,
            0.09175,
            0.0875,
            0.08275,
            0.07625,
            0.075,
            0.0725
        ],
        "time_series": [
            34.092394,
            34.159211,
            34.212069,
            34.261937,
            34.314795,
            34.364661,
            34.417521,
            34.469382,
            34.523238,
            34.587067
        ],
        "duration": 0.66921067237854
    },
    "-4361201509451323941": {
        "dataset": "abalone",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "regression",
        "parameters": "iterations_10_learning_rate_0.03_max_depth_6_",
        "scores": [
            3.24294,
            3.19003,
            3.14026,
            3.09172,
            3.04524,
            3.00128,
            2.95913,
            2.91798,
            2.87908,
            2.84184
        ],
        "time_series": [
            5.930265,
            5.93226,
            5.934256,
            5.936249,
            5.937247,
            5.938244,
            5.939241,
            5.942235,
            5.945226,
            5.94722
        ],
        "duration": 0.03290987014770508
    },
    "8415933441484535031": {
        "dataset": "abalone",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "regression",
        "parameters": "iterations_10_learning_rate_0.07_max_depth_6_",
        "scores": [
            3.17122,
            3.05504,
            2.95409,
            2.86166,
            2.77707,
            2.70374,
            2.63634,
            2.57536,
            2.52327,
            2.48072
        ],
        "time_series": [
            5.984121,
            5.986116,
            5.987113,
            5.98811,
            5.991105,
            5.993097,
            5.995092,
            5.997086,
            5.999081,
            6.001076
        ],
        "duration": 0.023936748504638672
    },
    "-3977648608556361744": {
        "dataset": "abalone",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "regression",
        "parameters": "iterations_10_learning_rate_0.15_max_depth_6_",
        "scores": [
            3.03322,
            2.82284,
            2.65957,
            2.53484,
            2.43898,
            2.37132,
            2.31161,
            2.26836,
            2.23918,
            2.21614
        ],
        "time_series": [
            6.033988,
            6.034985,
            6.036979,
            6.039977,
            6.040968,
            6.042964,
            6.043961,
            6.045956,
            6.04795,
            6.049945
        ],
        "duration": 0.023935794830322266
    },
    "-6162547031092323545": {
        "dataset": "letters",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "multiclass",
        "parameters": "iterations_10_learning_rate_0.03_max_depth_6_",
        "scores": [
            0.16525,
            0.1475,
            0.13225,
            0.129,
            0.12325,
            0.12175,
            0.11675,
            0.1135,
            0.111,
            0.1065
        ],
        "time_series": [
            6.442898,
            6.484783,
            6.518692,
            6.54961,
            6.583519,
            6.627402,
            6.674276,
            6.721151,
            6.754063,
            6.786975
        ],
        "duration": 0.47568583488464355
    },
    "2313309948557373686": {
        "dataset": "letters",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "multiclass",
        "parameters": "iterations_10_learning_rate_0.07_max_depth_6_",
        "scores": [
            0.15275,
            0.133,
            0.1215,
            0.1135,
            0.10325,
            0.09925,
            0.09475,
            0.0895,
            0.088,
            0.087
        ],
        "time_series": [
            6.936575,
            6.982453,
            7.016361,
            7.050271,
            7.08418,
            7.117093,
            7.153994,
            7.189898,
            7.223807,
            7.258715
        ],
        "duration": 0.45777463912963867
    },
    "2849945075747933157": {
        "dataset": "letters",
        "algorithm_name": "lightgbm-CPU",
        "task_type": "multiclass",
        "parameters": "iterations_10_learning_rate_0.15_max_depth_6_",
        "scores": [
            0.14975,
            0.1245,
            0.10825,
            0.09575,
            0.09175,
            0.0875,
            0.08275,
            0.07625,
            0.075,
            0.0725
        ],
        "time_series": [
            7.433251,
            7.490096,
            7.53398,
            7.576864,
            7.61576,
            7.655654,
            7.697541,
            7.732448,
            7.765361,
            7.800267
        ],
        "duration": 0.5076420307159424
    }
}